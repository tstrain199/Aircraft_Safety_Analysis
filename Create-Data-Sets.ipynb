{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Cleaning and Preparation\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import glob\n",
    "import re\n",
    "from bs4 import BeautifulSoup \n",
    "import requests\n",
    "import pickle \n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load in T100 data from csv files\n",
    "\n",
    "files_li = glob.glob('zippedData/T_T100D*.2.csv') \n",
    "bts_df = pd.DataFrame(pd.read_csv(files_li[0])) \n",
    "for i in range(1,len(files_li)): \n",
    "    data = pd.read_csv(files_li[i]) \n",
    "    df1 = pd.DataFrame(data) \n",
    "    bts_df = pd.concat([df1,bts_df],axis=0, ignore_index=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keep only top 40 used aircraft models\n",
    "\n",
    "bts_40 = bts_df['AIRCRAFT_TYPE'].value_counts().head(40).index.to_list()\n",
    "indexNum = bts_df[~bts_df['AIRCRAFT_TYPE'].isin(bts_40)].index\n",
    "bts_df.drop(indexNum , inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get list of top 40 aircraft names for data cleaning\n",
    "\n",
    "#bts_des = bts_df['AIRCRAFT_TYPE'].value_counts.to_frame()\n",
    "bts_des = pd.DataFrame(pd.unique(bts_df['AIRCRAFT_TYPE']), columns =['AIRCRAFT_TYPE'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BTS uses number code to identify aircraft type in it's flight data. The legend is in a seperate csv file. \n",
    "# Load in the legend for aircraft type. \n",
    "\n",
    "ac_df = pd.read_csv('zippedData/L_AIRCRAFT_TYPE.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge flight data with aircfaft type. This will match BTS type names to the fligt data.\n",
    "\n",
    "bts_des = pd.merge(bts_des,ac_df,left_on='AIRCRAFT_TYPE',right_on='Code')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop piston aircraft\n",
    "#bts_des = bts_des.drop(index=[5, 10, 18, 26, 29, 31, 37])\n",
    "i = bts_des[(bts_des['Code'] == 40)].index\n",
    "j = bts_des[(bts_des['Code'] == 35)].index\n",
    "k = bts_des[(bts_des['Code'] == 194)].index\n",
    "l = bts_des[(bts_des['Code'] == 79)].index\n",
    "m = bts_des[(bts_des['Code'] == 479)].index\n",
    "n = bts_des[(bts_des['Code'] == 415)].index\n",
    "o = bts_des[(bts_des['Code'] == 416)].index\n",
    "bts_des = bts_des.drop(i)\n",
    "bts_des = bts_des.drop(j)\n",
    "bts_des = bts_des.drop(k)\n",
    "bts_des = bts_des.drop(l)\n",
    "bts_des = bts_des.drop(m)\n",
    "bts_des = bts_des.drop(n)\n",
    "bts_des = bts_des.drop(o)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "common_words = ['BOEING','CHEROKEE', 'AIRBUS', 'INDUSTRIE', 'CANADAIR', 'EMBRAER', 'MCDONNELL', 'DOUGLAS', \n",
    "                'DE', 'HAVILLAND', 'BEAVER', 'SUPER', 'NAVAJO', 'EM', 'ER', 'BEECH']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "common_words_eng = ['ILYUSHIN', 'ANTONOV', 'JUNKERS', 'LOCKHEED', 'BOEING','AIRBUS', 'INDUSTRIE', \n",
    "                    'CANADAIR', 'EMBRAER', 'STATIONAIR','MCDONNELL', 'DOUGLAS', 'DE', 'HAVILLAND', 'BEAVER',\n",
    "                    'SUPER','NAVAJO', 'EM', 'ER', 'BEECH', 'CRAFT', 'BOMBARDIER','CANADA']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "common_words_emi = ['TRENT', 'CFMI', 'PRATT & WHITNEY', 'GENERAL ELECTRIC', 'CANADA',\n",
    "                    'ROLLSROYCE', 'LYCOMING', 'ALLISON', 'GARRETT', 'CONTINENTAL', 'IAE']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def short_name(name, x):\n",
    "    if len(name) >= x:\n",
    "        short_name = name[:x]\n",
    "        return(short_name)\n",
    "    return(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_dash(name):\n",
    "    name = name.replace('-', '')\n",
    "    return(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_upper(name):\n",
    "    name = name.upper()\n",
    "    return(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_date(date):\n",
    "    date = date.astype('datetime64[ns]')\n",
    "    return(date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_slash(name):\n",
    "    res = re.match(r\"^[^/]*\", name)\n",
    "    return(str(res.group())) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_common(name, common_w):\n",
    "    for common in common_w:\n",
    "        name = name.replace(common, '')\n",
    "    return(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_space(name):\n",
    "    name = name.replace(' ', \"\")\n",
    "    return(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def convert_boeing(name):\n",
    "    if re.match(r\"^(7)(.)(7)\", name):\n",
    "        name = name[:3]\n",
    "    return name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_crj(name):\n",
    "    if re.match(r\"^RJ\", name):\n",
    "        name = name.replace('RJ', 'CRJ')\n",
    "    return name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bts_des.loc[bts_des['Code'] == 629, 'Description'] = 'Canadair RJ-200'\n",
    "bts_des.loc[bts_des['Code'] == 631, 'Description'] = 'Canadair RJ-700'\n",
    "bts_des.loc[bts_des['Code'] == 638, 'Description'] = 'Canadair RJ-900'\n",
    "bts_des.loc[bts_des['Code'] == 838, 'Description'] = 'Boeing 737-800'\n",
    "bts_des.loc[bts_des['Code'] == 674, 'Description'] = 'Embraer ERJ-130'\n",
    "bts_des.loc[bts_des['Code'] == 676, 'Description'] = 'Embraer ERJ-140'\n",
    "bts_des.loc[bts_des['Code'] == 675, 'Description'] = 'Embraer ERJ-145'\n",
    "bts_des.loc[bts_des['Code'] == 677, 'Description'] = 'Embraer ERJ-170'\n",
    "bts_des.loc[bts_des['Code'] == 678, 'Description'] = 'Embraer ERJ-190'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bts_des['Description'] = [convert_upper(x) for x in bts_des['Description']]\n",
    "bts_des['Description'] = [remove_slash(x) for x in bts_des['Description']]\n",
    "bts_des['Description'] = [remove_dash(x) for x in bts_des['Description']]\n",
    "bts_des['Description'] = [remove_common(x, common_words) for x in bts_des['Description']]\n",
    "bts_des['Description'] = [remove_space(x) for x in bts_des['Description']]\n",
    "bts_des['Description'] = [short_name(x, 4) for x in bts_des['Description']]\n",
    "bts_des['Description'] = [convert_boeing(x) for x in bts_des['Description']]\n",
    "bts_des['Description'] = [convert_crj(x) for x in bts_des['Description']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bts_df = pd.merge(bts_df,bts_des[['Code', 'Description']],left_on='AIRCRAFT_TYPE', right_on='Code')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bts_des.drop(['AIRCRAFT_TYPE', 'Code'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Data Set from CSV\n",
    "\n",
    "crash_df = pd.read_csv('zippedData/AviationData.csv', encoding='latin-1', dtype={6: str, 7: str, 14: str, 15: str,\n",
    "                                                                                 28: str})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "crash_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop rows before 2012 so we can match data by year in bts_df\n",
    "date_mask = (crash_df['Event.Date'] > '2011-12-31')\n",
    "\n",
    "# THIS RETURNS ALL ROWS GREATER THAN THE DATE PROVIDED ABOVE\n",
    "crash_df = crash_df.loc[date_mask]\n",
    "\n",
    "# Rows without an aircraft model type don't help use. Dropping these rows.\n",
    "crash_df = crash_df.dropna(subset=['Model'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some values in Make are upper, and some are mixed case. Change the Make column to all uppercase\n",
    "#crash_df['Make'] = crash_df['Make'].str.upper()\n",
    "\n",
    "# Convert Event.Date from string to datetime. Used to filter df on years\n",
    "crash_df['Event.Date'] = crash_df['Event.Date'].astype('datetime64[ns]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "crash_df['Model'] = [convert_upper(x) for x in crash_df['Model']]\n",
    "#crash_df['Event.Date'] = [convert_date(x) for x in crash_df['Event.Date']]\n",
    "crash_df['Model'] = [remove_slash(x) for x in crash_df['Model']]\n",
    "crash_df['Model'] = [remove_dash(x) for x in crash_df['Model']]\n",
    "crash_df['Model'] = [remove_common(x, common_words) for x in crash_df['Model']]\n",
    "crash_df['Model'] = [remove_space(x) for x in crash_df['Model']]\n",
    "crash_df['Model'] = [short_name(x, 4) for x in crash_df['Model']]\n",
    "crash_df['Model'] = [convert_boeing(x) for x in crash_df['Model']]\n",
    "#crash_df['Model'].replace('PA-', 'PA', inplace=True, regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def match_types(model):\n",
    "    for newmodel in bts_des['Description']:\n",
    "        if newmodel.startswith(model):\n",
    "            #print(f'Processing: {model} \\t:{newmodel}')\n",
    "            return newmodel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "crash_df['NewModel'] = [match_types(model) for model in crash_df['Model']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Engine Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In place of running this and making a web request, import the pickle file from below\n",
    "# Assign URL |\n",
    "#url = \"https://asn.flightsafety.org/database/engines/\"\n",
    "\n",
    "# Make a GET request to fetch the raw HTML content \n",
    "#html_content = requests.get(url).text \n",
    "\n",
    "# Parse the response with html.parser\n",
    "#soup = BeautifulSoup(html_content,\"html.parser\") \n",
    "\n",
    "# The data we need are wrapped in <a> tags. Grab all the <a> tags here and we'll filter later.\n",
    "#datas = soup.find_all(\"a\")\n",
    "\n",
    "\n",
    "#Make list of URLs and list oF Aircraft to create dictionary\n",
    "# k = []\n",
    "# v = []\n",
    "# for item in datas:\n",
    "#     if 'engine' in item['href']:\n",
    "#         k.append(item['href'])\n",
    "#         v.append(item.text)\n",
    "\n",
    "# lookup_dict = {'URL': k, 'Engine': v}\n",
    "\n",
    "\n",
    "#url_df = pd.DataFrame.from_dict(lookup_dict)\n",
    "\n",
    "# with open('lookup_dict.pkl', 'wb') as f:\n",
    "#     pickle.dump(lookup_dict, f)\n",
    "\n",
    "with open('zippedData/lookup_dict.pkl', 'rb') as f:\n",
    "    lookup_dict = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Take in the engine and retriev the matching data page with Aircraft data\n",
    "# Add Aircraft list from web a python list.\n",
    "# Return the python list\n",
    "\n",
    "# url_p1 = 'https://asn.flightsafety.org'\n",
    "# def lookup_ac(url_p2):\n",
    "#     return_list = []\n",
    "#     url = f'{url_p1}{url_p2}'\n",
    "#     sub_content = requests.get(url).text\n",
    "#     soup2 = BeautifulSoup(sub_content,\"html.parser\")\n",
    "#     u_list=soup2.find_all('ul')[1]\n",
    "#     i = 0 \n",
    "#     while i < len(u_list.select('li')):\n",
    "#         (u_list.select('li')[i].text)\n",
    "#         return_list.append(u_list.select('li')[i].text)\n",
    "#         i += 1\n",
    "#     return(return_list)\n",
    "\n",
    "# Create Aircraft column to list aircraft for each engine.\n",
    "#url_df['Aircraft'] = url_df['URL'].map(lookup_ac)\n",
    "\n",
    "# Save df to pickle file.\n",
    "#url_df.to_pickle('zippedData/url_df.pkl')\n",
    "\n",
    "with open('zippedData/url_df.pkl', 'rb') as f:\n",
    "    url_df = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a row for each aircraft for each engine. \n",
    "# Iterate through url_df['Aircraft'] column. For each element\n",
    "# in list, create a new row.\n",
    "\n",
    "engines = []\n",
    "aircraft = []\n",
    "for idx, row in url_df.iterrows():\n",
    "    for ac in row['Aircraft']:\n",
    "        engines.append(row['Engine'])\n",
    "        aircraft.append(ac)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dictionary from lists to load into dataFrame\n",
    "ac_eng_dict = {'Engine': engines, 'Aircraft': aircraft}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dataFrame from dictionary\n",
    "engines_df = pd.DataFrame.from_dict(ac_eng_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.loc[len(df.index)] = ['Amy', 89, 93] \n",
    "engines_df.loc[engines_df['Aircraft'] == 'Bombardier CRJ100 / 200 / 440'] = ['General Electric CF34','Canadair RJ-100']\n",
    "engines_df.loc[engines_df['Aircraft'] == 'Bombardier CRJ700'] = ['General Electric CF34','Canadair RJ-700']\n",
    "engines_df.loc[engines_df['Aircraft'] == 'Bombardier CRJ900'] = ['General Electric CF34','Canadair RJ-900']\n",
    "engines_df.loc[len(engines_df.index)] = ['General Electric CF34', 'Canadair RJ-200']\n",
    "engines_df.loc[len(engines_df.index)] = ['General Electric CF34', 'Canadair RJ-440']\n",
    "engines_df.loc[len(engines_df.index)] = ['General Electric CF34', 'Embraer ERJ-130']\n",
    "engines_df.loc[len(engines_df.index)] = ['General Electric CF34', 'Embraer ERJ-135']\n",
    "engines_df.loc[len(engines_df.index)] = ['General Electric CF34', 'Embraer ERJ-140']\n",
    "engines_df.loc[len(engines_df.index)] = ['General Electric CF34', 'Embraer ERJ-175']\n",
    "engines_df.loc[len(engines_df.index)] = ['General Electric CF34', 'Embraer ERJ-190']\n",
    "engines_df.loc[len(engines_df.index)] = ['Pratt & Whitney JT8D', 'McDonnell Douglas DC-9-80']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "engines_df['Aircraft'] = [convert_upper(x) for x in engines_df['Aircraft']]\n",
    "engines_df['Aircraft'] = [remove_slash(x) for x in engines_df['Aircraft']]\n",
    "engines_df['Aircraft'] = [remove_dash(x) for x in engines_df['Aircraft']]\n",
    "engines_df['Aircraft'] = [remove_common(x, common_words_eng) for x in engines_df['Aircraft']]\n",
    "engines_df['Aircraft'] = [remove_space(x) for x in engines_df['Aircraft']]\n",
    "engines_df['Aircraft'] = [short_name(x, 4) for x in engines_df['Aircraft']]\n",
    "engines_df['Aircraft'] = [convert_boeing(x) for x in engines_df['Aircraft']]\n",
    "engines_df['Aircraft'] = [convert_crj(x) for x in engines_df['Aircraft']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "engines_df['Engine_Name'] = [convert_upper(x) for x in engines_df['Engine']]\n",
    "engines_df['Engine_Name'] = [remove_slash(x) for x in engines_df['Engine_Name']]\n",
    "engines_df['Engine_Name'] = [remove_dash(x) for x in engines_df['Engine_Name']]\n",
    "engines_df['Engine_Name'] = [remove_common(x, common_words_emi) for x in engines_df['Engine_Name']]\n",
    "engines_df['Engine_Name'] = [remove_common(x, common_words_emi) for x in engines_df['Engine_Name']]\n",
    "engines_df['Engine_Name'] = [remove_space(x) for x in engines_df['Engine_Name']]\n",
    "engines_df['Engine_Name'] = [short_name(x, 5) for x in engines_df['Engine_Name']]\n",
    "#engines_df['Engine_Name'] = [convert_boeing(x) for x in engines_df['Engine_Name']]\n",
    "#engines_df['Engine_Name'] = [convert_crj(x) for x in engines_df['Engine_Name']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bts_des = pd.merge(bts_des, engines_df,left_on='Description', right_on='Aircraft', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bts_des.drop_duplicates(inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Emissions Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "emissions_df = pd.read_excel('zippedData/edb-emissions-databank_v30__web_.xlsx',\n",
    "                             sheet_name='Gaseous Emissions and Smoke', \n",
    "                             usecols=('A:D, AJ'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "emissions_df['Engine Identification'] = [convert_upper(x) for x in emissions_df['Engine Identification']]\n",
    "emissions_df['Engine Identification'] = [remove_slash(x) for x in emissions_df['Engine Identification']]\n",
    "emissions_df['Engine Identification'] = [remove_dash(x) for x in emissions_df['Engine Identification']]\n",
    "emissions_df['Engine Identification'] = [remove_common(x, common_words_emi) for x in emissions_df['Engine Identification']]\n",
    "emissions_df['Engine Identification'] = [remove_space(x) for x in emissions_df['Engine Identification']]\n",
    "emissions_df['Engine Identification'] = [short_name(x, 5) for x in emissions_df['Engine Identification']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "emissions_df.at[527,'Engine Identification'] = 'PW100'\n",
    "emissions_df.at[611,'Engine Identification'] = 'PW200'\n",
    "emissions_df.at[633,'Engine Identification'] = 'PW400'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def match_engine(str1):\n",
    "    tmp_df = pd.DataFrame()\n",
    "    mask = tmp_df['engine_id_starts_with_CFM'] = list( \n",
    "        map(lambda x: x.startswith(str1), emissions_df['Engine Identification'])) \n",
    "    filtered_df = emissions_df[mask]\n",
    "    #return(filtered_df.at[0,1]['CO Dp/Foo Avg (g/kN)']).head(1)\n",
    "    if filtered_df.shape[0] < 1:\n",
    "        return(0)\n",
    "    return(filtered_df.iat[0,4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bts_des['CO2'] = [match_engine(x) for x in bts_des['Engine_Name']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_best_eng(aircraft):\n",
    "    ac_ser = bts_des.loc[bts_des['Aircraft'] == aircraft]\n",
    "    return(ac_ser.sort_values('CO2')[:1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some rows have NaN for values. Replace these with 0 value. \n",
    "crash_df['Total.Fatal.Injuries'] = crash_df['Total.Fatal.Injuries'].fillna(0)\n",
    "crash_df['Total.Serious.Injuries'] = crash_df['Total.Serious.Injuries'].fillna(0)\n",
    "crash_df['Total.Minor.Injuries'] = crash_df['Total.Minor.Injuries'].fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Our scoring system will use 3 points for fatality; 1 point for serious injury and .5 points for minor injury.\n",
    "crash_df['Injury_Score'] = crash_df['Total.Fatal.Injuries'].map(lambda x: x*3)\n",
    "crash_df['Injury_Score'] = crash_df['Injury_Score'] + crash_df['Total.Serious.Injuries']\n",
    "crash_df['Injury_Score'] = crash_df['Injury_Score'] + (crash_df['Total.Minor.Injuries'] * .5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_score = crash_df.groupby('NewModel')['Injury_Score'].sum().to_frame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_score['Count'] = bts_df.groupby('Description').size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_score['Rating'] = (total_score['Injury_Score'] / total_score['Count']) * 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_score = pd.merge(total_score, bts_des[['CO2', 'Aircraft', 'Engine']], left_on='NewModel', right_on='Aircraft', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_score.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_score.sort_values(['CO2', 'Rating'], ascending=[True, True])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(total_score['CO2'], total_score['Rating'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Airport Data Analysis\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ap_df = pd.read_csv('zippedData/us-airports.csv')\n",
    "cbsa_df = pd.read_csv('zippedData/cbsa-est2023-alldata.csv', encoding='latin-1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ap_df = ap_df.dropna(subset=['gps_code'])\n",
    "ap_df.drop(['continent', 'country_name', 'home_link', 'wikipedia_link', 'last_updated'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ap_df = ap_df[(ap_df['type'] == 'medium_airport') | (ap_df['type'] == 'large_airport')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cbsa_df.drop(cbsa_df[cbsa_df['POPESTIMATE2023'] <= 550000].index, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_state(str1):\n",
    "    res = str1.split(',')\n",
    "    return(res)\n",
    "cbsa_df['STATE'] = [(get_state(x))[1].strip() for x in cbsa_df['NAME']]\n",
    "cbsa_df['CITY'] = [(get_state(x))[0].split('-')[0] for x in cbsa_df['NAME']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result2 = ap_df.groupby(['municipality', 'local_region'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result2.get_group(('Cleveland','OH'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract keys from groups\n",
    "keys = result2.groups.keys()\n",
    " \n",
    "for i in keys:\n",
    "    print(result2.get_group(i))\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (leanr-env)",
   "language": "python",
   "name": "learn-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

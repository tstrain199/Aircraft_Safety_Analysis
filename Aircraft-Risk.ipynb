{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project Title\n",
    "**Author**: Todd Strain\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview\n",
    "Virtucon have decided to diversify and explore new reevnue strams by offering flight operation services\n",
    "for commercial and private enterprises. The company is concerned about the risks and environmental impact\n",
    "of this new line of business. Since the company has little knowledge of these risks we've undertaken an\n",
    "analysis of these issues. Three datasets were used to determin which models of aircraft are the safest to\n",
    "operate while having an acceptable level of environmental impact. The result was the Canadaair RJ190 was the\n",
    "safetst aircraft to operate. The <blank> was the most enironmentaly friendly aircraft. Our reecommendation is \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Business Problem\n",
    "Virtucon wants to diversify it's business and introduce new revenu streams by operating aircraft for commercial \n",
    "and private enterprises. They want to know the safest and aircraft to operate with the least environmenatl impact.\n",
    "To answer that question we used the Bureau of Transportation Statistics (BTS) formula:\n",
    "\n",
    "*“Rates are computed by dividing the number of Fatalities, Seriously injured persons, Total accidents, and Fatal accidents by the number of Aircraft-miles, Aircraft departures, or Flight hours.” *\n",
    "\n",
    "To determine environmntal impact we used data for popular aircraft from EASA."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Understanding\n",
    "For aircraft safty we used two datasets NTSB aircraft crash database and BTS T-100 Domestic Segmaent database for the 10 years preceeding 2024.\n",
    "\n",
    "The NTSB crash database includes aviation accident data from 1962 to 2023 about civil aviation accidents and selected incidents in the United States and international waters. We are most interested in the number of accidents per aircraft model type, and the number and grade of passenger injuries.\n",
    "\n",
    "The BTS T-100 Domestic Segment database includes on-flight origin and destination records. From this dataset we use the make and model of aircraft, and the number of flight instances. \n",
    "\n",
    "In both datasets we've selected data from 2014-2024 (most recently reported.) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Structures\n",
    "- **df**            DataFrame. Full AviationData.csv provided by project. Containf flight crash data.\n",
    "- **bts_df**        DataFrame. 5 years of flight data from BTS. Contains airline flight data.\n",
    "- **ac_df**         DataFrame. Legend that matches aircraft code in bts_df to Make/Model.\n",
    "- **joined_df**     DataFrame. Merged bts_df with Make/Model from ac_df.\n",
    "- **bts_actype**    DataFrame. List of aircraft from joined_df. Used to create spreadsheet for standarized names.\n",
    "- **bts_map_df**    DataFrame. Imported from bts_actype spreadsheet with actype converted to standardized names.\n",
    "- **bts_map_dic**   Dict. bts_map_df converted to dictionary so it can be added as new column to joined_df.\n",
    "- **crash_actype**  DataFrame. Copy of Make, Model columns from df. Later updated with standardized model name.\n",
    "- **custom_ac**     DataFrame. Copy of Model column from crash_actype with value counts.\n",
    "- **custom_ac_li**  List. custom_ac converted to list. Used to update crash_actype individual Make with 'Custom'.\n",
    "- **df3**           DataFrame. df merged with updated crash_actype to get standardized names. Added InjuryScore column.\n",
    "- **total_score**   DataFrame. Aircraft type and score totaled from df3.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Clenaing and Preparation\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-2-46a298358933>:1: DtypeWarning: Columns (6,7,28) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv('zippedData/AviationData.csv', encoding='latin-1')\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('zippedData/AviationData.csv', encoding='latin-1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Event.Id', 'Investigation.Type', 'Accident.Number', 'Event.Date',\n",
       "       'Location', 'Country', 'Latitude', 'Longitude', 'Airport.Code',\n",
       "       'Airport.Name', 'Injury.Severity', 'Aircraft.damage',\n",
       "       'Aircraft.Category', 'Registration.Number', 'Make', 'Model',\n",
       "       'Amateur.Built', 'Number.of.Engines', 'Engine.Type', 'FAR.Description',\n",
       "       'Schedule', 'Purpose.of.flight', 'Air.carrier', 'Total.Fatal.Injuries',\n",
       "       'Total.Serious.Injuries', 'Total.Minor.Injuries', 'Total.Uninjured',\n",
       "       'Weather.Condition', 'Broad.phase.of.flight', 'Report.Status',\n",
       "       'Publication.Date'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(88889, 31)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop rows before 2012 so we can match data by year in bts_df\n",
    "date_mask = (df['Event.Date'] > '2011-12-31')\n",
    "# THIS RETURNS ALL ROWS GREATER THAN THE DATE PROVIDED ABOVE\n",
    "df = df.loc[date_mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rows without an aircraft model type don't help use. Dropping these rows.\n",
    "df = df.dropna(subset=['Model'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some values in Make are upper, and some are mixed case. Change the Make column to all uppercase\n",
    "df['Make'] = df['Make'].str.upper()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Convert Event.Date from string to datetime. Used to filter df on years\n",
    "df['Event.Date'] = df['Event.Date'].astype('datetime64[ns]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load in T100 data from csv files\n",
    "files_li = glob.glob('zippedData/T_T100D*.2.csv') \n",
    "bts_df = pd.DataFrame(pd.read_csv(files_li[0])) \n",
    "for i in range(1,len(files_li)): \n",
    "    data = pd.read_csv(files_li[i]) \n",
    "    df1 = pd.DataFrame(data) \n",
    "    bts_df = pd.concat([df1,bts_df],axis=0, ignore_index=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['DISTANCE', 'AIR_TIME', 'UNIQUE_CARRIER_NAME', 'ORIGIN', 'DEST',\n",
       "       'AIRCRAFT_TYPE', 'YEAR', 'MONTH', 'DISTANCE_GROUP'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bts_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "YEAR\n",
       "2022    411461\n",
       "2019    395552\n",
       "2021    384081\n",
       "2016    382397\n",
       "2018    380238\n",
       "2017    373658\n",
       "2015    370162\n",
       "2014    358366\n",
       "2012    347452\n",
       "2013    343132\n",
       "2020    297833\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bts_df['YEAR'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "UNIQUE_CARRIER_NAME\n",
       "Southwest Airlines Co.                  381471\n",
       "Delta Air Lines Inc.                    348303\n",
       "United Air Lines Inc.                   301166\n",
       "SkyWest Airlines Inc.                   237574\n",
       "American Airlines Inc.                  188528\n",
       "Federal Express Corporation             186737\n",
       "ExpressJet Airlines LLC d/b/a aha!      129799\n",
       "Hageland Aviation Service               122776\n",
       "Allegiant Air                           122148\n",
       "United Parcel Service                   107885\n",
       "Republic Airline                        104241\n",
       "Alaska Airlines Inc.                     98684\n",
       "Envoy Air                                92405\n",
       "Frontier Airlines Inc.                   85449\n",
       "Endeavor Air Inc.                        85005\n",
       "Spirit Air Lines                         79363\n",
       "Grant Aviation                           72125\n",
       "JetBlue Airways                          69685\n",
       "PSA Airlines Inc.                        68853\n",
       "Ryan Air f/k/a Arctic Transportation     65132\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bts_df['UNIQUE_CARRIER_NAME'].value_counts().head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Because the Aviation Crash Data and BTS use different model names for Aircraft type we need to standardize on a set of names.\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BTS uses number code to identify aircraft type in it's flight data. The legend is in a seperate csv file. \n",
    "# Load in the legend for aircraft type. \n",
    "ac_df = pd.read_csv('zippedData/L_AIRCRAFT_TYPE.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge flight data with aircfaft type. This will match BTS type names to the fligt data.\n",
    "joined_df = pd.merge(bts_df,ac_df,left_on='AIRCRAFT_TYPE',right_on='Code')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Making a list of aircraft from the flight data. We use this list to assign standard names.\n",
    "bts_actype = joined_df[['Description']].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop duplicates from flight aircraft \n",
    "bts_actype.drop_duplicates(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write this to Excel so we can standardize aircraft names.\n",
    "# bts_actype.to_excel('zippedData/bts_actype2.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in our standardized label spreadsheet after edit\n",
    "bts_map_df = pd.read_excel('zippedData/bts_actype.2.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert standardized name spreadsheet to mapping dictionary\n",
    "bts_map_dic = dict(zip(bts_map_df.Description, bts_map_df.Model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Map original aircraft names to standardized name and put in new column\n",
    "joined_df['NewModel'] = joined_df['Description'].map(bts_map_dic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['DISTANCE', 'AIR_TIME', 'UNIQUE_CARRIER_NAME', 'ORIGIN', 'DEST',\n",
       "       'AIRCRAFT_TYPE', 'YEAR', 'MONTH', 'DISTANCE_GROUP', 'Code',\n",
       "       'Description', 'NewModel'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joined_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert some intergers to strings\n",
    "joined_df['NewModel'] = joined_df['NewModel'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Making a list of aircraft from the NTSB crash data. \n",
    "crash_actype = df[['Make', 'Model']].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We really want to do this on crash_actype\n",
    "#df['Model'].replace('-', '', inplace=True)\n",
    "#df['Model'].replace('/', '', inplace=True)\n",
    "crash_actype['Model'].replace('-', '', inplace=True, regex=True)\n",
    "crash_actype['Model'].replace('/', '', inplace=True, regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop duplicates from the crash_actype df.\n",
    "crash_actype.drop_duplicates(inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get value counts so we can drop single instance aircraft.\n",
    "custom_ac = crash_actype['Model'].value_counts().to_frame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert custom_ac to list. Used to update crash_actype individual Make with 'Custom'.\n",
    "custom_ac = custom_ac[custom_ac['count'] > 2]\n",
    "custom_ac_li = custom_ac.index.to_list()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lots of duplicates after replacing Make with 'Custom'. Drop duplicates from the crash_actype df\n",
    "crash_actype.drop_duplicates(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace individual Maker with 'Custom'\n",
    "for model in custom_ac_li:\n",
    "    crash_actype.loc[crash_actype['Model'] == model, 'Make'] = 'Custom'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Model\n",
       "RV6A             23\n",
       "SONEX            20\n",
       "CHALLENGER II    19\n",
       "RV7              16\n",
       "SEAREY           15\n",
       "                 ..\n",
       "200D              1\n",
       "PA28R  201T       1\n",
       "EMB 135KL         1\n",
       "OH 13HM74A        1\n",
       "M8 EAGLE          1\n",
       "Name: count, Length: 4072, dtype: int64"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "crash_actype['Model'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' \n",
    "This function will \n",
    "1) take in a model string from crash_actype \n",
    "2) match it with a newmodel from joined_df\n",
    "3) update crash_actype with new_model column\n",
    "TODO: Replace with faster version.\n",
    "'''\n",
    "def match_types(model):\n",
    "    for newmodel in joined_df['NewModel']:\n",
    "        if model.startswith(newmodel):\n",
    "            #print(f'Processing: {model} \\t:{newmodel}')\n",
    "            return newmodel\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "    Creating the NewModel colum takes a lot of CPU and time. It's been saved as a pickle file so we can just\n",
    "    read it in and save time.\n",
    "\"\"\"\n",
    "#crash_actype['NewModel'] = [match_types(model) for model in crash_actype['Model']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save df to pickle file.\n",
    "#crash_actype.to_pickle('zippedData/crash_actype.2.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 551,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in pickle file\n",
    "crash_actype = pd.read_pickle(r'zippedData/crash_actype.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5506, 3)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "crash_actype.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Modeling\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 826,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NewModel\n",
       "737         888665\n",
       "A320        642230\n",
       "208         219309\n",
       "RJ200       195787\n",
       "757         178044\n",
       "ERJ175      173038\n",
       "RJ700       169427\n",
       "MD80        156614\n",
       "145         153205\n",
       "206         139183\n",
       "CRJ900      137718\n",
       "767         104339\n",
       "A300         65703\n",
       "PA31         63511\n",
       "EMB170       57466\n",
       "747          44479\n",
       "1900         44466\n",
       "DASH8        39522\n",
       "190          38706\n",
       "PC12         36956\n",
       "212          32537\n",
       "MD11         28799\n",
       "DC10         27205\n",
       "DHC2         26880\n",
       "140          24471\n",
       "DC9          22351\n",
       "nan          20616\n",
       "777          19567\n",
       "PA32         16926\n",
       "135          15880\n",
       "King Air     15591\n",
       "GA8          12387\n",
       "402          12274\n",
       "727          12106\n",
       "GIV          11323\n",
       "340B         11120\n",
       "A330         10326\n",
       "C185         10051\n",
       "FALCON        8001\n",
       "EMB120        7929\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 826,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# List the top 40 flown aircraft types\n",
    "joined_df['NewModel'].value_counts().head(40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 827,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge Aircraft Data with crash_actype to get standardized Aircraft Types\n",
    "df3 = pd.merge(df, crash_actype,left_on='Model',right_on='Model', suffixes=(\"_l\", \"_r\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 830,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_40 = joined_df['NewModel'].value_counts().head(40).index.to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 831,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3 = df3.loc[df3['NewModel'].isin(top_40)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 832,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2357, 33)"
      ]
     },
     "execution_count": 832,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df3.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 833,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some rows have NaN for values. Replace these with 0 value. \n",
    "df3['Total.Fatal.Injuries'] = df3['Total.Fatal.Injuries'].fillna(0)\n",
    "df3['Total.Serious.Injuries'] = df3['Total.Serious.Injuries'].fillna(0)\n",
    "df3['Total.Minor.Injuries'] = df3['Total.Minor.Injuries'].fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 834,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 834,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check replacement\n",
    "df3['Total.Fatal.Injuries'].isna().sum()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 836,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Our scoring system will use 3 points for fatality; 1 point for serious injury and .5 points for minor injury.\n",
    "df3['Injury_Score'] = df3['Total.Fatal.Injuries'].map(lambda x: x*3)\n",
    "df3['Injury_Score'] = df3['Injury_Score'] + df3['Total.Serious.Injuries']\n",
    "df3['Injury_Score'] = df3['Injury_Score'] + (df3['Total.Minor.Injuries'] * .5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 839,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Total.Fatal.Injuries</th>\n",
       "      <th>Total.Serious.Injuries</th>\n",
       "      <th>Total.Minor.Injuries</th>\n",
       "      <th>Injury_Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2071</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2072</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2073</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2074</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2075</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2076</th>\n",
       "      <td>0.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2077</th>\n",
       "      <td>127.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>381.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2078</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2079</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2080</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2081</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2082</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2083</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2084</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2085</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2086</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2087</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2088</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2089</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2090</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2091</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2092</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2093</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2094</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2095</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2096</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2097</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2098</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2099</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2100</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2101</th>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2102</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2103</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2104</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2105</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2106</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2107</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2108</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2109</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2110</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2111</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2112</th>\n",
       "      <td>0.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2113</th>\n",
       "      <td>0.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>14.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2114</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2115</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2116</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2117</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2118</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2119</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2120</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Total.Fatal.Injuries  Total.Serious.Injuries  Total.Minor.Injuries   \n",
       "2071                   0.0                     0.0                   0.0  \\\n",
       "2072                   0.0                     0.0                   0.0   \n",
       "2073                   0.0                     0.0                   0.0   \n",
       "2074                   0.0                     0.0                   0.0   \n",
       "2075                   0.0                     0.0                   0.0   \n",
       "2076                   0.0                    13.0                   0.0   \n",
       "2077                 127.0                     0.0                   0.0   \n",
       "2078                   0.0                     0.0                   0.0   \n",
       "2079                   0.0                     0.0                   0.0   \n",
       "2080                   0.0                     0.0                   0.0   \n",
       "2081                   0.0                     0.0                   0.0   \n",
       "2082                   0.0                     0.0                   0.0   \n",
       "2083                   0.0                     0.0                   1.0   \n",
       "2084                   0.0                     0.0                   0.0   \n",
       "2085                   0.0                     0.0                   0.0   \n",
       "2086                   0.0                     0.0                   0.0   \n",
       "2087                   0.0                     0.0                   0.0   \n",
       "2088                   0.0                     0.0                   0.0   \n",
       "2089                   0.0                     0.0                   0.0   \n",
       "2090                   0.0                     1.0                   2.0   \n",
       "2091                   0.0                     0.0                   0.0   \n",
       "2092                   0.0                     0.0                   0.0   \n",
       "2093                   0.0                     0.0                   0.0   \n",
       "2094                   0.0                     0.0                   0.0   \n",
       "2095                   0.0                     0.0                   0.0   \n",
       "2096                   0.0                     0.0                   0.0   \n",
       "2097                   0.0                     0.0                   0.0   \n",
       "2098                   0.0                     0.0                   0.0   \n",
       "2099                   0.0                     0.0                   0.0   \n",
       "2100                   0.0                     0.0                   0.0   \n",
       "2101                   0.0                     2.0                   0.0   \n",
       "2102                   0.0                     0.0                   0.0   \n",
       "2103                   0.0                     0.0                   0.0   \n",
       "2104                   0.0                     0.0                   0.0   \n",
       "2105                   0.0                     0.0                   0.0   \n",
       "2106                   0.0                     0.0                   0.0   \n",
       "2107                   0.0                     0.0                   0.0   \n",
       "2108                   0.0                     0.0                   0.0   \n",
       "2109                   0.0                     0.0                   0.0   \n",
       "2110                   0.0                     0.0                   0.0   \n",
       "2111                   0.0                     0.0                   0.0   \n",
       "2112                   0.0                    20.0                   0.0   \n",
       "2113                   0.0                    14.0                   1.0   \n",
       "2114                   0.0                     0.0                   0.0   \n",
       "2115                   0.0                     0.0                   0.0   \n",
       "2116                   0.0                     0.0                   0.0   \n",
       "2117                   0.0                     0.0                   0.0   \n",
       "2118                   0.0                     0.0                   0.0   \n",
       "2119                   0.0                     0.0                   0.0   \n",
       "2120                   0.0                     0.0                   0.0   \n",
       "\n",
       "      Injury_Score  \n",
       "2071           0.0  \n",
       "2072           0.0  \n",
       "2073           0.0  \n",
       "2074           0.0  \n",
       "2075           0.0  \n",
       "2076          13.0  \n",
       "2077         381.0  \n",
       "2078           0.0  \n",
       "2079           0.0  \n",
       "2080           0.0  \n",
       "2081           0.0  \n",
       "2082           0.0  \n",
       "2083           0.5  \n",
       "2084           0.0  \n",
       "2085           0.0  \n",
       "2086           0.0  \n",
       "2087           0.0  \n",
       "2088           0.0  \n",
       "2089           0.0  \n",
       "2090           2.0  \n",
       "2091           0.0  \n",
       "2092           0.0  \n",
       "2093           0.0  \n",
       "2094           0.0  \n",
       "2095           0.0  \n",
       "2096           0.0  \n",
       "2097           0.0  \n",
       "2098           0.0  \n",
       "2099           0.0  \n",
       "2100           0.0  \n",
       "2101           2.0  \n",
       "2102           0.0  \n",
       "2103           0.0  \n",
       "2104           0.0  \n",
       "2105           0.0  \n",
       "2106           0.0  \n",
       "2107           0.0  \n",
       "2108           0.0  \n",
       "2109           0.0  \n",
       "2110           0.0  \n",
       "2111           0.0  \n",
       "2112          20.0  \n",
       "2113          14.5  \n",
       "2114           0.0  \n",
       "2115           0.0  \n",
       "2116           0.0  \n",
       "2117           0.0  \n",
       "2118           0.0  \n",
       "2119           0.0  \n",
       "2120           0.0  "
      ]
     },
     "execution_count": 839,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df3.loc[:,['Total.Fatal.Injuries', 'Total.Serious.Injuries','Total.Minor.Injuries','Injury_Score']].head(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 840,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_score = df3.groupby('NewModel')['Injury_Score'].sum().to_frame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 841,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.frame.DataFrame"
      ]
     },
     "execution_count": 841,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(total_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 848,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_score['Count'] = joined_df.groupby('NewModel').size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 849,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NewModel\n",
       "105            71\n",
       "12             88\n",
       "124           601\n",
       "135         15880\n",
       "140         24471\n",
       "            ...  \n",
       "S76           166\n",
       "SIDDELEY      216\n",
       "TBM850        302\n",
       "TURBINE      1442\n",
       "nan         20616\n",
       "Length: 122, dtype: int64"
      ]
     },
     "execution_count": 849,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joined_df.groupby('NewModel').size()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 850,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Injury_Score', 'Count', 'Rating'], dtype='object')"
      ]
     },
     "execution_count": 850,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_score.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 856,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_score['Rating'] = (total_score['Injury_Score'] / total_score['Count']) * 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 857,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Injury_Score</th>\n",
       "      <th>Count</th>\n",
       "      <th>Rating</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NewModel</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>A300</th>\n",
       "      <td>0.0</td>\n",
       "      <td>65703</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EMB120</th>\n",
       "      <td>0.0</td>\n",
       "      <td>7929</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DC9</th>\n",
       "      <td>0.0</td>\n",
       "      <td>22351</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>0.0</td>\n",
       "      <td>153205</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ERJ175</th>\n",
       "      <td>0.5</td>\n",
       "      <td>173038</td>\n",
       "      <td>0.002890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MD11</th>\n",
       "      <td>1.0</td>\n",
       "      <td>28799</td>\n",
       "      <td>0.034723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>757</th>\n",
       "      <td>8.0</td>\n",
       "      <td>178044</td>\n",
       "      <td>0.044933</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MD80</th>\n",
       "      <td>14.0</td>\n",
       "      <td>156614</td>\n",
       "      <td>0.089392</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>190</th>\n",
       "      <td>4.0</td>\n",
       "      <td>38706</td>\n",
       "      <td>0.103343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>747</th>\n",
       "      <td>12.0</td>\n",
       "      <td>44479</td>\n",
       "      <td>0.269790</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1900</th>\n",
       "      <td>24.0</td>\n",
       "      <td>44466</td>\n",
       "      <td>0.539738</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>767</th>\n",
       "      <td>81.0</td>\n",
       "      <td>104339</td>\n",
       "      <td>0.776316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A320</th>\n",
       "      <td>528.5</td>\n",
       "      <td>642230</td>\n",
       "      <td>0.822914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>727</th>\n",
       "      <td>10.5</td>\n",
       "      <td>12106</td>\n",
       "      <td>0.867339</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FALCON</th>\n",
       "      <td>7.5</td>\n",
       "      <td>8001</td>\n",
       "      <td>0.937383</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>212</th>\n",
       "      <td>31.0</td>\n",
       "      <td>32537</td>\n",
       "      <td>0.952761</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>King Air</th>\n",
       "      <td>18.0</td>\n",
       "      <td>15591</td>\n",
       "      <td>1.154512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>777</th>\n",
       "      <td>30.5</td>\n",
       "      <td>19567</td>\n",
       "      <td>1.558747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PC12</th>\n",
       "      <td>82.0</td>\n",
       "      <td>36956</td>\n",
       "      <td>2.218855</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A330</th>\n",
       "      <td>25.5</td>\n",
       "      <td>10326</td>\n",
       "      <td>2.469494</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PA31</th>\n",
       "      <td>167.0</td>\n",
       "      <td>63511</td>\n",
       "      <td>2.629466</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>402</th>\n",
       "      <td>34.5</td>\n",
       "      <td>12274</td>\n",
       "      <td>2.810820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>208</th>\n",
       "      <td>677.0</td>\n",
       "      <td>219309</td>\n",
       "      <td>3.086969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140</th>\n",
       "      <td>82.0</td>\n",
       "      <td>24471</td>\n",
       "      <td>3.350905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>737</th>\n",
       "      <td>3541.0</td>\n",
       "      <td>888665</td>\n",
       "      <td>3.984629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GA8</th>\n",
       "      <td>57.0</td>\n",
       "      <td>12387</td>\n",
       "      <td>4.601598</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GIV</th>\n",
       "      <td>72.0</td>\n",
       "      <td>11323</td>\n",
       "      <td>6.358739</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DHC2</th>\n",
       "      <td>174.0</td>\n",
       "      <td>26880</td>\n",
       "      <td>6.473214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PA32</th>\n",
       "      <td>250.5</td>\n",
       "      <td>16926</td>\n",
       "      <td>14.799716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>206</th>\n",
       "      <td>2598.0</td>\n",
       "      <td>139183</td>\n",
       "      <td>18.666073</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Injury_Score   Count     Rating\n",
       "NewModel                                 \n",
       "A300               0.0   65703   0.000000\n",
       "EMB120             0.0    7929   0.000000\n",
       "DC9                0.0   22351   0.000000\n",
       "145                0.0  153205   0.000000\n",
       "ERJ175             0.5  173038   0.002890\n",
       "MD11               1.0   28799   0.034723\n",
       "757                8.0  178044   0.044933\n",
       "MD80              14.0  156614   0.089392\n",
       "190                4.0   38706   0.103343\n",
       "747               12.0   44479   0.269790\n",
       "1900              24.0   44466   0.539738\n",
       "767               81.0  104339   0.776316\n",
       "A320             528.5  642230   0.822914\n",
       "727               10.5   12106   0.867339\n",
       "FALCON             7.5    8001   0.937383\n",
       "212               31.0   32537   0.952761\n",
       "King Air          18.0   15591   1.154512\n",
       "777               30.5   19567   1.558747\n",
       "PC12              82.0   36956   2.218855\n",
       "A330              25.5   10326   2.469494\n",
       "PA31             167.0   63511   2.629466\n",
       "402               34.5   12274   2.810820\n",
       "208              677.0  219309   3.086969\n",
       "140               82.0   24471   3.350905\n",
       "737             3541.0  888665   3.984629\n",
       "GA8               57.0   12387   4.601598\n",
       "GIV               72.0   11323   6.358739\n",
       "DHC2             174.0   26880   6.473214\n",
       "PA32             250.5   16926  14.799716\n",
       "206             2598.0  139183  18.666073"
      ]
     },
     "execution_count": 857,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_score.sort_values('Rating')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 911,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 911,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Broad.phase.of.flight'].notna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (leanr-env)",
   "language": "python",
   "name": "learn-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
